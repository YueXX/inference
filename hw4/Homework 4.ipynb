{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Homework 4\n",
    "## Alex Pine, akp258"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Topic modeling code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hack to get python to look for the pip modules before the OS X versions.\n",
    "# This ensures the newest version of the 'six' library is used, which gensim requires.\n",
    "import sys\n",
    "sys.path.insert(0, '/Library/Python/2.7/site-packages')\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.a: Prepare document corpus\n",
    "Using the UC Irvine's \"Daily Kos\" weblog corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "corpus = corpora.UciCorpus('docword.kos.txt', fname_vocab='vocab.kos.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.b Prepare Document Corpus\n",
    "Train LDA models with default parameters. gensim's LDA module defaults to 100 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    }
   ],
   "source": [
    "# Defaults to num_topics=100\n",
    "default_model = models.LdaMulticore(corpus, id2word=corpus.create_dictionary(), workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topics: 100\n",
      "Topic 1 : 0.013*bush + 0.011*campaign + 0.007*kerry + 0.007*democratic + 0.006*senate + 0.005*time\n",
      "Topic 2 : 0.016*november + 0.011*bush + 0.008*republicans + 0.008*poll + 0.007*senate + 0.007*house\n",
      "Topic 3 : 0.014*iraq + 0.011*kerry + 0.010*bush + 0.008*war + 0.005*news + 0.005*campaign\n",
      "Topic 4 : 0.027*bush + 0.010*kerry + 0.007*war + 0.007*general + 0.006*campaign + 0.005*people\n",
      "Topic 5 : 0.007*bush + 0.006*iraq + 0.005*campaign + 0.005*democrats + 0.005*senate + 0.004*news\n",
      "Topic 6 : 0.012*dean + 0.008*iowa + 0.008*kerry + 0.007*campaign + 0.007*bush + 0.007*general\n",
      "Topic 7 : 0.008*bush + 0.008*democratic + 0.007*war + 0.007*iraq + 0.005*november + 0.005*kerry\n",
      "Topic 8 : 0.017*bush + 0.013*kerry + 0.008*million + 0.007*republicans + 0.006*administration + 0.005*senate\n",
      "Topic 9 : 0.008*bush + 0.007*primary + 0.006*states + 0.006*iraq + 0.006*democratic + 0.006*house\n",
      "Topic 10 : 0.016*bush + 0.009*kerry + 0.007*iraq + 0.007*state + 0.006*war + 0.005*house\n",
      "Topic 11 : 0.013*bush + 0.008*poll + 0.007*kerry + 0.007*november + 0.007*house + 0.007*president\n",
      "Topic 12 : 0.018*bush + 0.012*kerry + 0.007*iraq + 0.007*war + 0.006*dean + 0.005*poll\n",
      "Topic 13 : 0.025*bush + 0.009*kerry + 0.007*administration + 0.006*people + 0.006*general + 0.005*president\n",
      "Topic 14 : 0.015*kerry + 0.012*edwards + 0.012*dean + 0.010*democratic + 0.008*primary + 0.008*bush\n",
      "Topic 15 : 0.013*party + 0.012*bush + 0.011*democratic + 0.006*state + 0.006*kerry + 0.006*war\n",
      "Topic 16 : 0.023*november + 0.011*bush + 0.007*media + 0.007*senate + 0.007*poll + 0.006*democratic\n",
      "Topic 17 : 0.016*bush + 0.010*kerry + 0.007*administration + 0.005*war + 0.005*time + 0.005*vote\n",
      "Topic 18 : 0.007*bush + 0.006*house + 0.006*people + 0.005*national + 0.005*democratic + 0.005*party\n",
      "Topic 19 : 0.020*bush + 0.019*kerry + 0.010*democratic + 0.008*percent + 0.008*house + 0.007*poll\n",
      "Topic 20 : 0.010*war + 0.010*bush + 0.009*iraq + 0.007*cheney + 0.007*campaign + 0.006*president\n",
      "Topic 21 : 0.014*bush + 0.009*kerry + 0.008*house + 0.008*november + 0.007*general + 0.006*democratic\n",
      "Topic 22 : 0.007*iraq + 0.007*bush + 0.006*republicans + 0.006*state + 0.005*party + 0.005*war\n",
      "Topic 23 : 0.025*bush + 0.016*kerry + 0.012*percent + 0.009*poll + 0.008*president + 0.006*war\n",
      "Topic 24 : 0.018*bush + 0.015*kerry + 0.009*iraq + 0.007*war + 0.007*november + 0.007*poll\n",
      "Topic 25 : 0.016*kerry + 0.008*edwards + 0.007*dean + 0.007*clark + 0.006*war + 0.006*poll\n",
      "Topic 26 : 0.016*november + 0.008*bush + 0.007*house + 0.006*governor + 0.006*state + 0.006*poll\n",
      "Topic 27 : 0.012*bush + 0.009*november + 0.009*party + 0.008*house + 0.007*war + 0.007*republicans\n",
      "Topic 28 : 0.019*bush + 0.009*iraq + 0.008*kerry + 0.007*president + 0.006*people + 0.006*war\n",
      "Topic 29 : 0.020*bush + 0.014*kerry + 0.007*poll + 0.006*president + 0.006*democratic + 0.006*dean\n",
      "Topic 30 : 0.016*bush + 0.014*kerry + 0.007*war + 0.006*iraq + 0.006*million + 0.005*administration\n",
      "Topic 31 : 0.019*kerry + 0.013*bush + 0.008*democratic + 0.008*poll + 0.008*dean + 0.007*edwards\n",
      "Topic 32 : 0.007*state + 0.007*kerry + 0.006*election + 0.006*vote + 0.006*senate + 0.005*republican\n",
      "Topic 33 : 0.010*bush + 0.010*republican + 0.007*states + 0.007*republicans + 0.007*senate + 0.006*state\n",
      "Topic 34 : 0.020*bush + 0.009*administration + 0.007*dean + 0.005*party + 0.004*media + 0.004*democrats\n",
      "Topic 35 : 0.010*bush + 0.006*president + 0.006*campaign + 0.005*voters + 0.005*iraq + 0.004*states\n",
      "Topic 36 : 0.016*iraq + 0.011*bush + 0.010*war + 0.007*president + 0.006*kerry + 0.005*states\n",
      "Topic 37 : 0.017*bush + 0.016*kerry + 0.007*democratic + 0.007*house + 0.006*president + 0.006*democrats\n",
      "Topic 38 : 0.012*kerry + 0.010*campaign + 0.009*dean + 0.007*bush + 0.006*democratic + 0.005*people\n",
      "Topic 39 : 0.022*bush + 0.010*kerry + 0.008*administration + 0.007*campaign + 0.006*president + 0.006*elections\n",
      "Topic 40 : 0.009*dean + 0.006*bush + 0.006*media + 0.005*campaign + 0.005*senate + 0.005*democratic\n",
      "Topic 41 : 0.021*bush + 0.016*november + 0.009*house + 0.008*democrats + 0.008*republicans + 0.007*poll\n",
      "Topic 42 : 0.017*kerry + 0.014*bush + 0.007*dean + 0.007*poll + 0.006*democratic + 0.006*general\n",
      "Topic 43 : 0.019*bush + 0.017*kerry + 0.008*campaign + 0.006*people + 0.006*general + 0.006*war\n",
      "Topic 44 : 0.007*kerry + 0.007*poll + 0.006*dean + 0.006*senate + 0.006*race + 0.006*democratic\n",
      "Topic 45 : 0.019*kerry + 0.017*bush + 0.012*poll + 0.011*november + 0.008*dean + 0.007*democratic\n",
      "Topic 46 : 0.024*bush + 0.008*iraq + 0.008*president + 0.007*war + 0.006*bin + 0.006*laden\n",
      "Topic 47 : 0.018*november + 0.009*house + 0.008*bush + 0.007*party + 0.007*democratic + 0.006*poll\n",
      "Topic 48 : 0.012*bush + 0.008*republicans + 0.008*house + 0.007*democrats + 0.006*iraq + 0.005*republican\n",
      "Topic 49 : 0.018*kerry + 0.014*bush + 0.010*dean + 0.009*edwards + 0.008*poll + 0.006*cheney\n",
      "Topic 50 : 0.007*november + 0.007*bush + 0.007*war + 0.005*house + 0.005*senate + 0.005*political\n",
      "Topic 51 : 0.007*campaign + 0.007*gotv + 0.007*democratic + 0.006*saudi + 0.005*media + 0.005*bush\n",
      "Topic 52 : 0.011*bush + 0.010*kerry + 0.006*iraq + 0.005*campaign + 0.005*court + 0.004*dean\n",
      "Topic 53 : 0.013*bush + 0.009*war + 0.008*iraq + 0.008*november + 0.006*president + 0.005*senate\n",
      "Topic 54 : 0.009*kerry + 0.008*house + 0.008*campaign + 0.008*bush + 0.007*state + 0.005*states\n",
      "Topic 55 : 0.012*kerry + 0.009*poll + 0.009*bush + 0.007*percent + 0.007*edwards + 0.006*polls\n",
      "Topic 56 : 0.023*november + 0.018*bush + 0.013*kerry + 0.008*general + 0.007*senate + 0.007*polls\n",
      "Topic 57 : 0.009*state + 0.008*states + 0.007*house + 0.007*senate + 0.007*poll + 0.007*democratic\n",
      "Topic 58 : 0.013*november + 0.010*bush + 0.006*house + 0.005*election + 0.005*poll + 0.005*democratic\n",
      "Topic 59 : 0.008*bush + 0.007*democratic + 0.007*party + 0.006*november + 0.006*democrats + 0.006*campaign\n",
      "Topic 60 : 0.023*bush + 0.011*kerry + 0.008*administration + 0.006*general + 0.006*war + 0.005*iraq\n",
      "Topic 61 : 0.013*iraq + 0.011*war + 0.010*bush + 0.006*poll + 0.005*people + 0.004*nader\n",
      "Topic 62 : 0.015*bush + 0.010*kerry + 0.008*war + 0.007*iraq + 0.006*republican + 0.006*general\n",
      "Topic 63 : 0.011*kerry + 0.009*bush + 0.007*dean + 0.007*people + 0.006*democratic + 0.006*general\n",
      "Topic 64 : 0.013*bush + 0.007*war + 0.006*state + 0.006*iraq + 0.006*house + 0.006*senate\n",
      "Topic 65 : 0.020*kerry + 0.016*november + 0.011*dean + 0.011*bush + 0.007*war + 0.006*primary\n",
      "Topic 66 : 0.008*bush + 0.007*kerry + 0.006*general + 0.006*senate + 0.006*iraq + 0.004*time\n",
      "Topic 67 : 0.016*bush + 0.009*kerry + 0.007*percent + 0.007*democratic + 0.006*party + 0.006*democrats\n",
      "Topic 68 : 0.009*gotv + 0.008*republicans + 0.008*democratic + 0.008*kerry + 0.008*party + 0.007*dean\n",
      "Topic 69 : 0.025*bush + 0.016*kerry + 0.009*poll + 0.007*democratic + 0.007*time + 0.007*republicans\n",
      "Topic 70 : 0.010*percent + 0.009*bush + 0.009*general + 0.009*november + 0.007*senate + 0.007*nader\n",
      "Topic 71 : 0.011*house + 0.010*bush + 0.010*november + 0.007*kerry + 0.005*republicans + 0.005*democrats\n",
      "Topic 72 : 0.027*november + 0.009*senate + 0.008*house + 0.007*bush + 0.007*democratic + 0.007*poll\n",
      "Topic 73 : 0.014*bush + 0.010*kerry + 0.009*democratic + 0.008*iraq + 0.007*million + 0.006*campaign\n",
      "Topic 74 : 0.009*kerry + 0.009*bush + 0.008*democratic + 0.007*people + 0.006*democrats + 0.005*party\n",
      "Topic 75 : 0.019*bush + 0.018*kerry + 0.008*president + 0.007*dean + 0.006*poll + 0.006*general\n",
      "Topic 76 : 0.026*bush + 0.008*campaign + 0.008*november + 0.007*democratic + 0.006*kerry + 0.006*poll\n",
      "Topic 77 : 0.010*bush + 0.010*kerry + 0.009*war + 0.007*iraq + 0.006*campaign + 0.006*democratic\n",
      "Topic 78 : 0.014*bush + 0.012*kerry + 0.012*campaign + 0.007*general + 0.006*john + 0.005*iraq\n",
      "Topic 79 : 0.015*bush + 0.009*edwards + 0.006*john + 0.006*war + 0.006*kerry + 0.005*attacks\n",
      "Topic 80 : 0.011*bush + 0.011*november + 0.010*poll + 0.010*kerry + 0.006*news + 0.006*vote\n",
      "Topic 81 : 0.010*november + 0.008*iraq + 0.008*war + 0.008*bush + 0.005*democratic + 0.004*percent\n",
      "Topic 82 : 0.017*bush + 0.013*november + 0.012*kerry + 0.006*poll + 0.005*iraq + 0.005*general\n",
      "Topic 83 : 0.009*bush + 0.006*bunning + 0.005*people + 0.005*war + 0.004*poll + 0.004*campaign\n",
      "Topic 84 : 0.016*november + 0.012*bush + 0.006*war + 0.006*polls + 0.006*general + 0.006*republicans\n",
      "Topic 85 : 0.018*november + 0.015*bush + 0.012*kerry + 0.009*house + 0.006*general + 0.006*democrats\n",
      "Topic 86 : 0.013*bush + 0.007*republican + 0.006*general + 0.006*kerry + 0.006*war + 0.005*democratic\n",
      "Topic 87 : 0.035*november + 0.011*republicans + 0.011*poll + 0.009*bush + 0.007*governor + 0.007*electoral\n",
      "Topic 88 : 0.021*dean + 0.013*kerry + 0.009*campaign + 0.008*people + 0.007*bush + 0.006*president\n",
      "Topic 89 : 0.015*bush + 0.014*kerry + 0.008*percent + 0.007*iraq + 0.007*democratic + 0.006*poll\n",
      "Topic 90 : 0.009*war + 0.009*democrats + 0.008*iraq + 0.007*democratic + 0.006*house + 0.006*bush\n",
      "Topic 91 : 0.025*bush + 0.017*november + 0.008*kerry + 0.008*house + 0.007*republicans + 0.006*poll\n",
      "Topic 92 : 0.023*bush + 0.011*kerry + 0.008*war + 0.008*president + 0.007*iraq + 0.007*general\n",
      "Topic 93 : 0.022*november + 0.013*bush + 0.009*house + 0.008*kerry + 0.007*republicans + 0.007*war\n",
      "Topic 94 : 0.026*bush + 0.014*kerry + 0.012*percent + 0.008*poll + 0.006*voters + 0.006*iraq\n",
      "Topic 95 : 0.011*bush + 0.007*specter + 0.007*poll + 0.006*toomey + 0.005*campaign + 0.005*democratic\n",
      "Topic 96 : 0.006*delay + 0.006*republicans + 0.006*democratic + 0.006*house + 0.006*party + 0.006*november\n",
      "Topic 97 : 0.009*bush + 0.007*democratic + 0.007*poll + 0.006*percent + 0.006*kerry + 0.006*party\n",
      "Topic 98 : 0.025*kerry + 0.016*dean + 0.014*edwards + 0.010*democratic + 0.010*november + 0.009*clark\n",
      "Topic 99 : 0.012*iraq + 0.012*bush + 0.009*war + 0.007*november + 0.006*administration + 0.006*percent\n",
      "Topic 100 : 0.016*november + 0.010*poll + 0.009*kerry + 0.008*senate + 0.007*house + 0.006*democratic\n"
     ]
    }
   ],
   "source": [
    "def print_top_topics(model, num_topics):\n",
    "    print 'Number of topics:', model.num_topics\n",
    "    for i, topic in enumerate(default_model.print_topics(num_topics=num_topics, num_words=6)):\n",
    "        print 'Topic', str(i+1), ':', topic\n",
    "\n",
    "print_top_topics(default_model, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis\n",
    "The top five topics have a great deal of overlap. All of them are about the 2004 US presidential election. The first topic refers contains topics words related to electoral politics in general, and a few words specific to that election, such as \"marriage\" (as in \"gay marriage\", I assume). The second topic is similar, and the third topic is about presidential challengers \"Kerry\", \"Edwards\", and \"Dean. All the other topics seem to be minor variations on these themes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.c Try different values for num_topics\n",
    "\n",
    "Trying out the same model with 5, 10, and 50 different topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topics: 5\n",
      "Topic 1 : 0.007*november + 0.007*bush + 0.007*war + 0.005*house + 0.005*senate + 0.005*political\n",
      "Topic 2 : 0.014*bush + 0.010*kerry + 0.009*democratic + 0.008*iraq + 0.007*million + 0.006*campaign\n",
      "Topic 3 : 0.013*bush + 0.007*republican + 0.006*general + 0.006*kerry + 0.006*war + 0.005*democratic\n",
      "Topic 4 : 0.013*party + 0.012*bush + 0.011*democratic + 0.006*state + 0.006*kerry + 0.006*war\n",
      "Topic 5 : 0.023*bush + 0.011*kerry + 0.008*war + 0.008*president + 0.007*iraq + 0.007*general\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topics: 10\n",
      "Topic 1 : 0.023*november + 0.011*bush + 0.007*media + 0.007*senate + 0.007*poll + 0.006*democratic\n",
      "Topic 2 : 0.007*kerry + 0.007*poll + 0.006*dean + 0.006*senate + 0.006*race + 0.006*democratic\n",
      "Topic 3 : 0.013*bush + 0.007*war + 0.006*state + 0.006*iraq + 0.006*house + 0.006*senate\n",
      "Topic 4 : 0.008*bush + 0.007*democratic + 0.007*party + 0.006*november + 0.006*democrats + 0.006*campaign\n",
      "Topic 5 : 0.014*bush + 0.009*kerry + 0.008*house + 0.008*november + 0.007*general + 0.006*democratic\n",
      "Number of topics: 50\n",
      "Topic 1 : 0.035*november + 0.011*republicans + 0.011*poll + 0.009*bush + 0.007*governor + 0.007*electoral\n",
      "Topic 2 : 0.015*bush + 0.014*kerry + 0.008*percent + 0.007*iraq + 0.007*democratic + 0.006*poll\n",
      "Topic 3 : 0.010*november + 0.008*iraq + 0.008*war + 0.008*bush + 0.005*democratic + 0.004*percent\n",
      "Topic 4 : 0.013*bush + 0.011*campaign + 0.007*kerry + 0.007*democratic + 0.006*senate + 0.005*time\n",
      "Topic 5 : 0.021*bush + 0.016*november + 0.009*house + 0.008*democrats + 0.008*republicans + 0.007*poll\n"
     ]
    }
   ],
   "source": [
    "num_topics_list = [5, 10, 20]\n",
    "for num_topics in num_topics_list:\n",
    "    model = models.LdaMulticore(corpus, num_topics=num_topics, id2word=corpus.create_dictionary(), workers=4)\n",
    "    print_top_topics(model, num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO write up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code that reads in data files for question 4\n",
    "\n",
    "import os\n",
    "\n",
    "class Doc:\n",
    "    def __init__(self, num_topics, topic_priors, word_priors):\n",
    "        self.num_topics = num_topics\n",
    "        self.topic_priors = topic_priors  # alpha.\n",
    "        self.word_priors = word_priors  # beta\n",
    "        self.topic_dist = []  # theta. To be set via inference.\n",
    "        self.topics = []  # z. One for each key in topic_priors.\n",
    "    \n",
    "\n",
    "def parse_input_file(filename):\n",
    "    num_topics = 0\n",
    "    # Dirichlet hyperparams, aka alphas\n",
    "    topic_priors = []\n",
    "    # Beta prior for this document, words are rows, topic probabilities are columns\n",
    "    word_priors = {}\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        lines = [line for line in f]\n",
    "        num_topics = int(lines[0])\n",
    "        assert(num_topics > 0)\n",
    "        topic_priors = [float(tok.strip()) for tok in lines[1].split()]\n",
    "        assert(len(topic_priors) == num_topics)\n",
    "        for word_index, line in enumerate(lines[2:]): # TODO make this into a matrix\n",
    "            tokens = line.split()\n",
    "            word = tokens[0].strip()  # not used\n",
    "            word_probs = [float(tok.strip()) for tok in tokens[1:]]\n",
    "            assert(len(word_probs) == num_topics)\n",
    "            word_priors[word_index] = word_probs\n",
    "    return num_topics, topic_priors, word_priors\n",
    "\n",
    "\n",
    "# TODO unused?\n",
    "def read_input_files(directory):\n",
    "    docs = []\n",
    "    # Expect input files to end with \".ready\"\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.ready'):\n",
    "            full_path = directory + '/' + filename\n",
    "            num_topics, topic_priors, word_priors = parse_input_file(full_path)\n",
    "            docs.append(Doc(num_topics, topic_priors, word_priors))\n",
    "    # There should be 11 docs, corresponding to 11 files\n",
    "    kExpectedNumInputFiles = 11\n",
    "    assert(len(docs) == kExpectedNumInputFiles)\n",
    "    return docs\n",
    "    \n",
    "#docs = read_input_files('ps4_data')\n",
    "doc = Doc(*parse_input_file('ps4_data/abstract_nips17_NIPS2004_0237.txt.ready'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.random import mtrand\n",
    "\n",
    "# Sample a topic probability (theta) for the uncollapsed sampler.\n",
    "def sample_topic_dist(topic_priors, topics):\n",
    "    topic_counts = [0]*len(topic_priors)\n",
    "    for topic in topics:\n",
    "        topic_counts[topic] += 1\n",
    "    posterior_topic_priors = [prior + count\n",
    "                              for prior, count in zip(topic_priors, topic_counts)]\n",
    "    return mtrand.dirichlet(posterior_topic_priors) # TODO test this to ensure it returns what you think\n",
    "\n",
    "\n",
    "# Create the posterior probabilities for topics (z) for the uncollapsed sampler.\n",
    "def sample_posterior_topic(word_index, word_priors, topic_dist):\n",
    "    posterior_topic_probs = []\n",
    "    word_prior_list = word_priors[word_index]\n",
    "    for topic_index in range(len(topic_dist)):\n",
    "        numerator = word_prior_list[topic_index] * topic_dist[topic_index] \n",
    "        posterior_topic_probs.append(numerator)\n",
    "    denominator = sum(posterior_topic_probs)\n",
    "    posterior_topic_probs = [prob/denominator for prob in posterior_topic_probs]\n",
    "    category_counts = mtrand.multinomial(1, posterior_topic_probs)\n",
    "    for topic_index, sample_value in enumerate(category_counts):\n",
    "        if sample_value == 1:\n",
    "            return topic_index\n",
    "    raise Exception('Error occured while sampling topic')\n",
    "    \n",
    "\n",
    "\n",
    "def uncollapsed_gibbs_sampler(doc, num_iterations):\n",
    "    # Initialize the topic_dist and topics to dummy values to start.\n",
    "    initial_topic_dist = [1.0/doc.num_topics]*num_topics\n",
    "    initial_topics = [1]*len(doc.word_priors)\n",
    "    # create a list with a doc for each iteration.\n",
    "    samples = [(initial_topic_dist, initial_topics)] # TODO make this a named tuple for clarity\n",
    "    for iteration in range(num_iterations):\n",
    "        #TODOprint 'iteration', iteration\n",
    "        prev_topics = samples[-1][1]\n",
    "        # Sample topic distribution (theta)\n",
    "        topic_dist_sample = sample_topic_dist(doc.topic_priors, prev_topics)\n",
    "        topics_sample = list(prev_topics)\n",
    "        for i in range(len(topics_sample)):\n",
    "            # Sample each topic instantiation (z_{mn})\n",
    "            topics_sample[i] = sample_posterior_topic(i, doc.word_priors, topic_dist_sample)\n",
    "        # TODO not sure if this should be in the inner loop or not...    \n",
    "        samples.append((topic_dist_sample, topics_sample))\n",
    "    samples = samples[50:]  # Remove the 'burn' samples\n",
    "    return samples    \n",
    "\n",
    "samples = uncollapsed_gibbs_sampler(doc, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEACAYAAABbMHZzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUZz4hxjM3AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109894710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def uncollapsed_expected_value(samples):\n",
    "    average_thetas = [0.0]*len(samples[0][0])\n",
    "    for sample in samples:\n",
    "        sample_thetas = sample[0]\n",
    "        for i in range(len(average_thetas)):\n",
    "            average_thetas[i] += sample_thetas[i]\n",
    "    average_thetas = [theta/len(samples) for theta in average_thetas]\n",
    "    return average_thetas\n",
    "    \n",
    "expected_theta = uncollapsed_expected_value(samples)\n",
    "plt.plot(range(len(expected_theta)), expected_theta)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
